{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using Real-world Images\n",
    "The imitation of the classifier from a previous week was that it used a dataset of very uniformed images: clothing pictures framed in a 28x28 size.\n",
    "What happens if we use larger images and features can be in different locations?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding ImageGenerator\n",
    "You can point out to a directory and subdirectories of that will generate labels for you: Images -> Training/Validation -> Horses/Humans\n",
    "To load images using tensorflow:\n",
    "```jupyterpython\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting a training generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) # instantiate and normalize the data\n",
    "train_generator = train_datagen.flow_from_directory( # always point to a directory that contains subdirectories that contain images\n",
    "                                                    # names of subdirectories will be the labels of the images\n",
    "    directory='train_dir',\n",
    "    target_size=(300, 300), # input data has to be the same size; images are resized as they are loaded -> no need to pre-process images\n",
    "    batch_size=128, # images are loaded in batches to optimise performance\n",
    "    class_mode='binary' # just a binary classifier e.g. horse vs. human\n",
    ")\n",
    "\n",
    "# Setting up a validation generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='validation_dir', #points to a subdir with test images\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining a ConvNet to use complex images\n",
    "```jupyterpython\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    # 3 sets of convolution and pooling layers because images are more complex: 300x330x3 (rgb) instead of 28x28x1 (greyscale).\n",
    "    # As a result we end up with 35x35 images\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'), # only 1 neuron for 2 classes;  the sigmoid function is great for binary classification\n",
    "    # we still could use a sofmtax function with 2 neurons as before, but sigmoid is more efficient for a binary classification\n",
    ")\n",
    "```\n",
    "\n",
    "A journey of the image in a NN:\n",
    "```\n",
    "(300, 300, 3) -> (298, 298, 16) -> (149, 149, 16) -> (147, 147, 32) -> (73, 73, 32) -> (71, 71, 64) -> (35, 35, 64) -> (78400) -> (512) -> (1)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the ConvNet with fit_generator\n",
    "```jupyterpython\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "# use `binary_crossentropy` instead of `sparse_categorical_crossentropy` to support a binary choice\n",
    "# use RMSprop instead of Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc'])\n",
    "\n",
    "#Training the model:\n",
    "history = model.fit_generator( # note we use `fit_generator` instead of `fit` becasue we use a generator instead of data sets\n",
    "    train_generator, # set up earlier, streams images from a training directory with batch size of 128\n",
    "    steps_per_epoch=8, # 1024 images in a training directory, we load 128 of them at a time, so to load them all we need 8 batches\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator, # a validation set with 256 images in batches of 32\n",
    "    validation_steps=8, # 256/32=8\n",
    "    verbose=2 # how much to display when training is going on; with value of 2 we get a little less animation hiding epoch progress\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}